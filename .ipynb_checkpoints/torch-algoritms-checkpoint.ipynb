{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_regression, make_classification\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "\n",
    "X, y = make_regression(n_samples = 10_000, n_features = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to tensor \n",
    "\n",
    "X_train = torch.tensor(X_train, dtype = torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype = torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype = torch.float32).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test, dtype = torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8000, 10]), torch.Size([8000, 1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, n = X_train.shape\n",
    "m, n "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# forward prop \n",
    "\n",
    "# init weights \n",
    "theta = torch.zeros((n, 1))\n",
    "theta.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# optimize \n",
    "EPOCHS = 1000\n",
    "alpha = 0.01\n",
    "\n",
    "for _ in range(EPOCHS):\n",
    "    grad = torch.matmul(X_train.T , torch.matmul(X_train, theta) - y_train)\n",
    "    theta = theta - (1/m) * alpha * grad\n",
    "    #print(grad)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preds = torch.matmul(X_test, theta)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mean_squared_error(preds, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "r2_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, epochs = 1000, learning_rate = 0.01):\n",
    "        self.EPOCHS = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.theta = None \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.theta = torch.zeros(X.shape[1], 1)\n",
    "        self.m = X.shape[0]\n",
    "        for _ in range(self.EPOCHS):\n",
    "            grad = torch.matmul(X.T , torch.matmul(X, self.theta) - y)\n",
    "            self.theta = self.theta - (1/self.m) * self.learning_rate * grad\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return torch.matmul(X, self.theta)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.285438e-05"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999978996776"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification \n",
    "\n",
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples = 10_000, n_features = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to tensor \n",
    "\n",
    "X_train = torch.tensor(X_train, dtype = torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype = torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype = torch.int32).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test, dtype = torch.int32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + torch.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, epochs = 1000, learning_rate = 0.01):\n",
    "        self.EPOCHS = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.theta = None \n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + torch.exp(-z))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.theta = torch.zeros(X.shape[1], 1)\n",
    "        self.m = X.shape[0]\n",
    "        for _ in range(self.EPOCHS):\n",
    "            grad = torch.matmul(X.T, torch.subtract(self.sigmoid(torch.matmul(X, self.theta)), y))\n",
    "            self.theta = self.theta - 1/self.m * self.learning_rate * grad\n",
    "    \n",
    "    def predict(self, X, thres = 0.5):\n",
    "        logits = self.sigmoid(torch.matmul(X, self.theta))\n",
    "        return torch.where(logits >= thres, 1, 0)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.sigmoid(torch.matmul(X, self.theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.814"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8286852589641435"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8062015503875969"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples = 10_000, n_features = 10, n_classes = 6, n_informative = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5864, -0.0988,  0.1215,  1.0364, -0.5057,  0.2315, -0.4629, -1.1826,\n",
       "          1.0571,  0.2246],\n",
       "        [ 0.2954,  2.1849, -2.0943,  0.9532,  0.9859, -1.6039,  1.1547,  0.0166,\n",
       "         -0.5697, -2.7389],\n",
       "        [-1.5554, -1.7111,  0.2480, -0.8602,  0.2296, -0.6488,  4.9383,  2.8052,\n",
       "          3.2875,  1.1840],\n",
       "        [ 0.1422,  0.7758, -0.7399, -2.2201, -1.9224,  0.0311, -0.0227, -1.3554,\n",
       "          2.0010,  2.7935],\n",
       "        [ 2.4634,  1.2937, -0.1770, -2.2588, -0.4370, -0.0846, -0.4059,  1.4525,\n",
       "          1.6276, -1.2226]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to tensor \n",
    "\n",
    "X_train = torch.tensor(X_train, dtype = torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype = torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype = torch.int32).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test, dtype = torch.int32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means clustering intends to partition n objects into k clusters in which each object belongs to the cluster with the\n",
    "nearest mean\n",
    "\n",
    "1. Randomly initialize K cluster centroids μ1, μ2,…., μk ∈ Rn\n",
    "2. Repeat until convergence : {\n",
    "    • For every example i, set:\n",
    "    • For every k, set:\n",
    "    • μk := average (mean) of points assigned to the cluster k\n",
    "\n",
    "The K-means algorithm aims to choose centroids that minimize the inertia, or within-cluster sum of squared\n",
    "criterion:\n",
    "\n",
    "Euclidean distance\n",
    "Cluster assignment step\n",
    "Assign each data point to the nearest cluster whose\n",
    "mean has the least squared Euclidean distance\n",
    "Update centroid step ( ⇒ Move Centroid )\n",
    "Calculate the new means to be the centroids of the\n",
    "observations in the new clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init centroids\n",
    "\n",
    "K = 8\n",
    "centroids = torch.rand((K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2035, 0.6257, 0.1074, 0.6672, 0.9595, 0.2688, 0.4216, 0.1357])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 10)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, n = X_train.shape\n",
    "m, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6333],\n",
       "        [6661],\n",
       "        [5992],\n",
       "        [2932],\n",
       "        [7930],\n",
       "        [ 851],\n",
       "        [7058],\n",
       "        [1035]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(46) # set seed \n",
    "\n",
    "sampled_idx = torch.randint(low = 0, high = m, size = (K, 1))\n",
    "sampled_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids = X_train[sampled_idx].squeeze(1)\n",
    "centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(26)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(46) # set seed \n",
    "\n",
    "def l2(x1, x2):\n",
    "    return torch.sum(torch.pow(torch.subtract(x1, x2), 2))\n",
    "\n",
    "x1 = torch.randint(size = (3, 1), low = 1, high = 10)\n",
    "x2 = torch.randint(size = (3, 1), low = 1, high = 10)\n",
    "\n",
    "l2(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8000, 1])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_list = torch.zeros((m, 1))\n",
    "cluster_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all the traininig set \n",
    "for i in range(m):\n",
    "    \n",
    "    distances = torch.tensor([l2(X_train[i], c) for c in centroids])\n",
    "    target = torch.argmin(distances) \n",
    "    cluster_list[i] = target\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [3.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [0.],\n",
       "        [3.],\n",
       "        [6.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6., 7.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_list.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# update clusters centroids \n",
    "for c in cluster_list.unique():\n",
    "    \n",
    "    indices = torch.where(cluster_list == c)[0]\n",
    "    all_centroids = X_train[indices]\n",
    "    new_centroid = torch.mean(all_centroids, axis = 0)\n",
    "    \n",
    "    centroids[torch.tensor(c, dtype = torch.long)] = new_centroid\n",
    "    \n",
    "\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(c, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, K, EPOCHS = 1_000):\n",
    "        self.K = K \n",
    "        self.centroids = None\n",
    "        self.labels = None\n",
    "        self.EPOCHS = EPOCHS\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \n",
    "        # set seed to remove \n",
    "        torch.manual_seed(46) \n",
    "        \n",
    "        m, n = X.shape\n",
    "        \n",
    "        # init centroids and labels \n",
    "        self.centroids = X_train[torch.randint(low = 0, high = m, size = (self.K, 1))].squeeze(1)\n",
    "        self.labels = torch.zeros((m, 1))\n",
    "        \n",
    "        for _ in range(self.EPOCHS):\n",
    "            \n",
    "            # STEP: cluster assignment \n",
    "            for i in range(m): \n",
    "                distances = torch.tensor([l2(X[i], c) for c in self.centroids])\n",
    "                target = torch.argmin(distances) \n",
    "                self.labels[i] = target\n",
    "            \n",
    "            # STEP: update centroid\n",
    "            for c in self.labels.unique():\n",
    "    \n",
    "                indices = torch.where(self.labels == c)[0]\n",
    "                centroids_c = X[indices]\n",
    "                new_centroid = torch.mean(centroids_c, axis = 0)\n",
    "\n",
    "                centroids[torch.tensor(c, dtype = torch.long)] = new_centroid\n",
    "            \n",
    "    \n",
    "    @staticmethod\n",
    "    def l2(x1, x2):\n",
    "        return torch.sum(torch.pow(torch.subtract(x1, x2), 2))\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        m, n = X.shape\n",
    "        labels_predict = torch.zeros((m, 1))\n",
    "        for i in range(m): \n",
    "            distances = torch.tensor([l2(X[i], c) for c in self.centroids])\n",
    "            target = torch.argmin(distances) \n",
    "            labels_predict[i] = target\n",
    "        return labels_predict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(K = 8, EPOCHS=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "kmeans.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.],\n",
       "        [0.],\n",
       "        [7.],\n",
       "        ...,\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [7.]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples = 10_000, n_features = 10, n_classes = 2, n_informative = 2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to tensor \n",
    "\n",
    "X_train = torch.tensor(X_train, dtype = torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype = torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype = torch.int32).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test, dtype = torch.int32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 100]), torch.Size([1, 100]))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init weights \n",
    "\n",
    "m, n = X_train.shape\n",
    "h = 100\n",
    "w = torch.randn((n, h))\n",
    "b = torch.zeros((1, h))\n",
    "w.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.9179e-02,  1.7665e-01, -3.9683e-02,  1.1815e+00,  6.1865e-01,\n",
       "         -2.8597e-01, -8.7382e-01, -1.3391e-01,  3.1835e-01,  1.7576e+00,\n",
       "          7.9654e-01,  1.1319e-01, -4.6064e-01,  8.7135e-01, -3.9571e-01,\n",
       "         -3.3757e-01, -2.1783e-01, -1.6478e+00, -1.7674e+00,  2.6018e-01,\n",
       "          1.0148e+00, -1.1868e+00,  6.7569e-01, -8.0400e-01,  7.6749e-01,\n",
       "          1.9721e-01, -3.0124e+00,  3.9439e-01, -9.1483e-01,  1.8086e+00,\n",
       "         -2.5647e+00, -1.6861e-01, -1.1850e+00,  3.8863e-01, -3.4357e-01,\n",
       "          2.6745e-01, -1.9818e+00, -2.5244e+00,  1.0488e+00, -1.8041e+00,\n",
       "          1.4382e+00,  1.7830e+00, -1.2948e+00,  7.4135e-01,  1.1780e+00,\n",
       "          7.4472e-01, -1.2014e+00,  6.5801e-01, -1.4202e-01,  1.7001e+00,\n",
       "          1.5876e+00, -5.1928e-01, -9.6915e-02, -6.9006e-01, -1.2166e+00,\n",
       "         -3.8726e-01,  2.2322e-01,  1.7348e+00, -9.7534e-01,  6.8716e-01,\n",
       "          1.0828e+00,  1.9775e-01,  1.0076e+00, -7.4686e-01,  1.0910e+00,\n",
       "          1.5851e-01,  4.0228e-01,  6.1128e-01,  6.8239e-01, -8.8252e-01,\n",
       "          9.3417e-01,  7.2121e-01,  2.4656e-01,  1.5496e-01, -3.4256e-01,\n",
       "         -3.8569e-01, -8.1639e-01, -4.1722e-01, -9.9574e-01, -9.2959e-01,\n",
       "         -4.8739e-01,  1.1005e-01,  1.4825e+00,  1.0066e+00,  9.3523e-01,\n",
       "          1.2121e-01,  1.0630e+00, -8.0430e-01,  3.6998e-01,  1.2781e+00,\n",
       "         -9.5963e-01, -9.4687e-01, -1.2486e+00, -1.6737e-01,  9.0723e-01,\n",
       "         -4.0628e-01,  1.8100e-01,  1.1874e+00, -1.2977e-02,  1.6244e+00],\n",
       "        [-6.4152e-01,  4.6914e-01, -6.6329e-01,  9.1198e-01,  1.3884e-01,\n",
       "         -6.1496e-01, -1.1155e-01,  1.5433e-01, -5.7383e-01,  8.7135e-01,\n",
       "          6.7447e-01, -9.2694e-01,  2.5939e-01, -4.2066e-01,  1.6111e+00,\n",
       "          5.4581e-01,  2.0025e+00, -2.2360e+00,  4.9613e-01, -2.8017e-01,\n",
       "         -8.7275e-01, -1.6394e+00, -6.7672e-01,  1.7587e-01, -1.2205e+00,\n",
       "          7.5491e-01,  4.4856e-01,  1.7177e-01,  4.3916e-01,  9.2497e-01,\n",
       "         -8.0555e-02, -5.8096e-01, -1.7839e+00,  4.9712e-01, -5.6818e-01,\n",
       "         -3.3192e-01, -1.3981e-04, -4.6132e-02,  3.1338e-01, -2.5425e+00,\n",
       "         -5.4381e-01,  4.5278e-01,  8.6859e-01, -1.1507e+00,  9.6432e-01,\n",
       "         -6.9928e-02, -1.5479e-01, -1.8841e-01, -7.7631e-01,  2.9042e-01,\n",
       "          2.3070e-01,  2.9740e-01, -7.0918e-01,  1.6709e+00, -8.6289e-01,\n",
       "          8.5815e-02, -4.7908e-01,  6.7622e-01, -9.7651e-01,  7.6489e-01,\n",
       "         -1.1507e+00, -1.9640e+00, -4.6477e-01, -6.3262e-01, -4.6169e-01,\n",
       "          1.0528e+00, -1.8665e-01,  8.8416e-01,  1.3445e+00,  1.0977e+00,\n",
       "         -7.9018e-01,  1.5865e+00, -1.4193e+00, -8.3820e-01, -6.3301e-01,\n",
       "         -1.2534e+00,  1.7562e-01, -1.0468e+00, -1.5809e+00, -9.2477e-01,\n",
       "          7.5285e-01, -4.1167e-01,  3.6555e-01,  8.6857e-01, -4.3322e-01,\n",
       "          5.6329e-01, -1.9072e-01, -3.9861e-01, -2.0445e+00,  3.7142e-01,\n",
       "         -1.8393e-01,  1.8095e+00,  4.1331e-01, -2.5018e-01, -1.2277e+00,\n",
       "         -1.6840e+00, -1.1795e+00,  2.1825e-01,  9.5183e-01, -2.2916e-01],\n",
       "        [-2.5614e-01, -2.3583e+00, -6.2813e-01,  9.5482e-01, -1.7027e+00,\n",
       "          9.6130e-01,  2.4369e-01,  1.0137e+00, -1.2280e+00,  3.0557e-01,\n",
       "          1.5866e+00,  1.5624e+00, -5.2836e-01, -3.1330e-01, -9.2735e-01,\n",
       "          4.0609e-01,  1.1107e+00, -1.0715e+00, -7.0799e-01,  8.5531e-02,\n",
       "         -8.5019e-01,  2.3098e-01,  6.2772e-01,  1.2351e+00, -7.4401e-01,\n",
       "          3.3062e-01,  1.9398e+00, -2.0006e+00, -4.5642e-01,  1.4743e+00,\n",
       "         -1.3240e+00, -8.5053e-01,  1.8417e-01,  8.2364e-01, -3.8329e-01,\n",
       "          3.2397e-01, -1.6131e+00, -1.6493e+00,  1.3573e+00,  8.9071e-01,\n",
       "          5.3623e-01,  4.5580e-01, -6.8385e-01,  1.8310e+00, -9.2185e-01,\n",
       "          7.2122e-01, -2.2891e+00,  1.8205e-01,  7.2451e-01,  4.0080e-01,\n",
       "         -2.0207e+00,  1.0313e-01, -3.3265e-01,  2.2055e-01, -5.9224e-01,\n",
       "          1.4936e+00, -2.1622e-01, -1.0507e+00, -4.6481e-01, -7.5738e-01,\n",
       "         -5.8159e-01, -8.3639e-01, -2.4565e-01,  5.0694e-01,  3.5601e-02,\n",
       "          5.7842e-01, -2.1485e+00, -1.5688e+00,  1.7326e+00, -6.7172e-01,\n",
       "          7.5948e-01, -1.8302e+00,  3.7098e-01,  9.5916e-01, -8.3457e-02,\n",
       "          1.0212e+00, -1.3664e+00,  5.5036e-01,  8.9402e-01, -5.8570e-01,\n",
       "         -2.7586e-01,  2.0474e+00, -1.4034e+00,  3.6025e-04,  4.1621e-02,\n",
       "         -1.8792e-01, -9.7224e-01,  2.4213e-01,  7.8423e-01, -4.7495e-02,\n",
       "         -3.0061e-01,  1.4057e-01,  5.8904e-01, -1.4016e+00,  1.1770e+00,\n",
       "         -4.4193e-01,  1.0027e+00, -1.2861e-02, -7.3511e-01,  5.4030e-01],\n",
       "        [-1.2438e-02,  1.8263e+00, -6.2495e-01,  1.2250e+00, -3.1601e-01,\n",
       "         -2.1292e-01,  1.1277e+00,  1.1880e+00,  4.8862e-01, -1.3277e+00,\n",
       "          1.1460e+00,  2.1602e+00, -4.4338e-02,  8.8978e-01,  1.2762e+00,\n",
       "          1.5284e+00,  2.1097e-01,  4.5430e-01,  2.5055e+00,  3.9161e-01,\n",
       "          3.9506e-01, -6.7640e-01, -1.0340e+00,  3.7865e-02, -9.8722e-01,\n",
       "          5.9943e-01, -6.1976e-01, -1.2629e+00,  3.0394e-01,  5.3944e-01,\n",
       "          1.0456e+00,  4.6370e-01,  2.3619e+00,  1.3352e-01,  7.1223e-01,\n",
       "          6.2568e-01,  9.9689e-01, -8.7655e-01,  6.7900e-01, -1.8814e+00,\n",
       "         -1.2143e+00, -1.3594e+00,  9.1056e-01,  1.7859e+00, -1.6702e+00,\n",
       "         -8.6044e-02, -2.2187e-02,  1.1573e+00,  1.0550e+00, -1.4205e+00,\n",
       "          1.6647e-01,  6.5562e-01,  7.0588e-01,  5.3781e-01,  1.6702e-01,\n",
       "         -6.4093e-01,  9.9689e-01, -2.3650e+00,  2.1927e+00,  1.9216e+00,\n",
       "          8.6065e-02,  1.7725e+00, -1.8015e-01, -1.3803e+00,  5.3085e-01,\n",
       "         -1.0696e+00,  6.2439e-01,  3.1035e-01, -1.3570e-01, -1.0098e+00,\n",
       "         -1.8555e+00,  9.5024e-01, -1.2480e+00,  5.2710e-03,  9.3599e-01,\n",
       "         -1.5263e+00, -1.9049e+00,  2.3811e-01, -5.2701e-01,  2.9812e-01,\n",
       "         -8.5481e-01,  4.8073e-01,  8.8471e-01,  3.6721e-01,  6.0761e-01,\n",
       "          3.8187e-01, -8.6586e-01, -4.3964e-01,  1.9263e-03,  1.5164e+00,\n",
       "         -3.8468e-01,  2.7842e-01,  4.4027e-01,  1.2462e-01,  7.6818e-01,\n",
       "          2.0190e-01,  1.2192e-01, -8.1777e-01,  1.1449e+00, -8.1065e-01],\n",
       "        [ 6.9308e-01,  1.2733e+00, -6.8082e-01,  1.7760e+00,  6.5711e-03,\n",
       "         -4.8794e-02, -1.3525e+00,  3.6892e-01,  8.4193e-03, -9.0855e-01,\n",
       "          6.7664e-02,  2.1999e+00,  5.8866e-02, -8.5674e-01,  7.5357e-01,\n",
       "         -1.1755e+00, -6.7922e-01,  9.5556e-01,  1.3726e+00, -2.3554e-02,\n",
       "         -8.1874e-01,  1.1081e-01,  8.0158e-01, -9.6784e-01,  5.0844e-01,\n",
       "         -7.8986e-01, -1.0410e+00, -2.9666e+00, -4.9789e-01, -4.1363e-01,\n",
       "         -3.6954e-01,  3.5812e-01, -4.7274e-01,  4.9198e-01,  4.7286e-02,\n",
       "         -4.2611e-01, -1.6763e+00, -1.9488e+00, -9.3798e-01,  3.6234e-02,\n",
       "         -1.5699e+00, -1.1303e+00, -9.7413e-01, -3.9126e-01, -5.8901e-01,\n",
       "          4.3881e-01,  9.4010e-01,  6.3267e-01, -1.5900e+00, -2.3653e-01,\n",
       "          3.2725e-01,  9.6185e-01,  1.1971e+00,  2.9373e-01,  4.9500e-01,\n",
       "          2.0463e-01,  7.0714e-01, -5.1736e-01, -8.2849e-01,  1.3899e+00,\n",
       "         -4.6722e-01,  9.8363e-01,  2.1623e-01,  1.1214e+00, -2.1246e-01,\n",
       "         -2.2786e-01, -2.0606e-01,  1.5010e+00,  2.0525e+00,  1.9729e-01,\n",
       "         -1.2391e+00, -5.2035e-02,  1.9565e+00,  8.8183e-01,  1.4409e+00,\n",
       "         -1.2083e+00,  5.7534e-01, -3.1184e-01,  5.8731e-01, -1.3188e+00,\n",
       "         -8.8096e-03,  4.9102e-02, -3.9311e-01,  5.6191e-01, -2.5680e-01,\n",
       "          3.6246e-01,  5.6350e-01,  2.0879e-03, -2.2660e-01,  9.0047e-02,\n",
       "         -6.0039e-01,  2.5356e-01, -3.4078e-01,  2.3173e-01, -6.4503e-01,\n",
       "         -3.2524e-01,  9.9496e-01, -1.0147e+00, -6.5198e-01, -5.0398e-01],\n",
       "        [ 1.7906e-01,  1.6416e+00,  1.1957e-01,  6.5940e-01, -1.1247e+00,\n",
       "          3.5897e-01, -3.3396e-03,  4.7540e-01, -6.7214e-01, -4.2028e-01,\n",
       "          2.7395e-02,  4.3610e-01,  1.7323e+00, -6.1864e-02, -1.6491e-01,\n",
       "          1.0526e-01,  7.0153e-01, -1.4596e+00, -1.2346e+00,  5.7374e-01,\n",
       "          1.4358e+00,  9.9896e-01,  1.1949e+00, -2.6932e-01, -3.1811e-01,\n",
       "          3.7515e-01, -6.2892e-01, -1.0236e+00,  1.5276e+00,  7.8730e-01,\n",
       "          5.1423e-01,  1.2703e+00,  1.0578e+00, -1.0389e+00,  2.6853e-02,\n",
       "         -1.1730e+00, -1.5104e+00, -1.9887e-01, -3.5769e-01, -2.1800e-01,\n",
       "         -5.6077e-02,  3.2826e-01, -8.9366e-01, -2.3336e+00, -9.5310e-01,\n",
       "         -9.7816e-02,  5.4747e-01,  4.3827e-01, -9.0760e-01,  1.5352e+00,\n",
       "         -1.8270e+00, -9.5896e-01,  3.0922e-01,  4.0389e-01, -1.8428e+00,\n",
       "          3.2339e-01,  1.4894e+00, -9.8061e-01, -5.0446e-01, -6.7462e-01,\n",
       "          4.3613e-01, -8.3253e-01, -2.5292e-01, -3.4484e-01,  1.4514e+00,\n",
       "          1.0669e+00,  6.8671e-01, -2.2903e+00, -1.2860e+00, -1.3331e-01,\n",
       "         -4.5692e-02,  1.0787e-01, -6.9817e-01,  2.1086e+00, -6.1940e-01,\n",
       "         -4.3889e-01, -1.6997e+00, -1.8638e-01, -7.7751e-01, -5.4318e-01,\n",
       "         -9.7793e-01, -3.9301e-01, -4.5403e-01,  8.9094e-01,  1.4878e+00,\n",
       "         -9.8570e-01,  4.8655e-01,  8.4001e-01,  4.0736e-01, -1.9300e+00,\n",
       "          2.9786e-01, -1.1305e-01, -1.8488e+00,  2.5932e+00,  2.3917e+00,\n",
       "          1.5185e+00,  3.9254e-01,  4.3874e-01,  2.5727e-01,  1.4969e-01],\n",
       "        [ 1.6759e+00, -2.5336e-01,  7.4055e-01, -2.2375e-02,  2.2222e-01,\n",
       "          7.3862e-01, -7.8225e-01,  3.8501e-01,  3.2757e-01, -3.1407e-01,\n",
       "         -2.0197e+00,  4.1893e-01,  4.8817e-01,  8.5367e-01,  6.5989e-01,\n",
       "          1.0094e+00, -2.8680e-01,  5.0903e-01,  1.2222e+00,  1.8724e-01,\n",
       "         -5.5142e-01, -5.5638e-01,  2.8034e-01,  7.8840e-01, -1.6214e+00,\n",
       "          1.8603e-01,  8.8786e-01,  5.9282e-02,  1.7145e-01,  1.0361e+00,\n",
       "          4.5817e-01,  8.7201e-01, -8.8448e-01, -1.4863e+00,  2.6953e+00,\n",
       "          1.9105e-01,  4.1746e-01, -7.4945e-01,  1.3625e+00,  9.9230e-01,\n",
       "          9.4812e-01,  1.4656e+00,  2.0646e+00, -9.1171e-01, -7.7010e-01,\n",
       "          7.1725e-01, -4.9615e-01, -2.9287e-01,  4.2158e-01, -2.7836e-01,\n",
       "         -1.3922e+00, -5.4902e-02,  6.9444e-01,  1.1962e+00,  8.7594e-01,\n",
       "         -5.5470e-01, -3.8209e-01, -1.2744e-01, -5.2742e-01,  3.3037e-01,\n",
       "         -1.2458e+00, -6.6967e-01, -2.3312e+00, -3.5600e-01,  2.1247e+00,\n",
       "          7.3733e-01, -7.5511e-02,  8.6986e-01,  3.5770e-01, -3.7769e-03,\n",
       "          1.5401e+00,  1.9252e-01,  5.5815e-01,  1.2695e+00,  1.6728e+00,\n",
       "         -3.8790e-02,  2.7868e-01, -8.4216e-01, -3.1451e-02,  8.3450e-01,\n",
       "         -2.7034e-01, -3.3378e-02, -1.4757e+00, -1.0442e+00,  1.3545e+00,\n",
       "         -1.3041e+00,  1.3512e+00,  1.2308e+00, -8.1242e-01,  9.6722e-01,\n",
       "          1.0439e+00, -1.4415e+00, -6.7479e-01,  3.4709e-02, -1.2238e-01,\n",
       "         -4.8730e-01, -1.0023e+00, -1.8380e+00,  1.3939e+00,  4.4413e-02],\n",
       "        [ 5.0446e-01,  3.6801e-01,  1.9141e+00,  7.3940e-01, -1.0934e-01,\n",
       "          1.1158e+00,  2.6671e-01, -9.5099e-01,  9.3954e-01, -4.5113e-01,\n",
       "         -2.2617e+00, -7.2959e-01,  2.3039e+00, -1.2140e+00,  1.1090e-01,\n",
       "         -2.7558e-01,  4.0953e-01,  1.0195e+00,  3.4641e-01, -1.8508e+00,\n",
       "         -3.5466e-01, -6.1058e-03,  2.2053e+00,  1.1084e+00, -1.1441e+00,\n",
       "         -2.1160e+00, -2.8671e-01, -1.0978e+00, -5.2039e-01,  1.2577e+00,\n",
       "         -2.1782e-01, -2.3982e-01, -2.6256e-02,  4.0387e-01,  2.2550e-01,\n",
       "         -1.1431e+00,  1.0438e+00,  1.3140e+00, -1.2773e+00, -1.8433e+00,\n",
       "         -1.5260e-01, -1.7737e-01, -8.6304e-01,  3.9098e-01, -2.3495e-01,\n",
       "          1.9500e-01,  1.0172e+00,  2.0456e-01,  5.5522e-01, -9.5895e-01,\n",
       "          1.2434e+00,  1.2290e+00,  2.2640e+00,  2.2501e+00, -1.8631e+00,\n",
       "         -1.0824e+00,  3.2306e-02, -7.1951e-01,  8.8675e-02,  2.0724e+00,\n",
       "         -4.1061e-01, -6.9106e-02,  4.7224e-01,  7.5619e-01, -7.2201e-01,\n",
       "          1.1226e-01,  1.4002e+00,  3.7563e-01, -5.2768e-02,  1.5082e-03,\n",
       "          1.0960e+00, -6.0938e-02,  1.0271e-01, -1.0736e-01, -1.0812e+00,\n",
       "         -1.1228e+00, -4.0451e-01, -8.7739e-01, -2.0668e+00,  3.5980e+00,\n",
       "         -3.2063e-01, -6.3993e-01,  7.1093e-01,  7.7258e-01,  7.7595e-01,\n",
       "          4.8020e-01,  3.7617e-02,  5.2014e-01,  6.2543e-01,  1.3365e-01,\n",
       "          7.2687e-01, -9.4484e-01,  8.9492e-01, -7.3517e-01, -2.3398e-01,\n",
       "          4.4145e-01, -3.0531e-01,  2.5305e-01,  5.1931e-01, -1.9106e+00],\n",
       "        [ 5.5011e-01,  9.6932e-01,  9.6382e-01,  1.5727e+00, -9.0532e-01,\n",
       "         -2.3586e+00,  3.9588e-01,  7.2311e-02,  2.2576e+00, -1.0431e+00,\n",
       "          1.1160e+00, -8.7461e-01,  1.9144e-01,  8.3251e-01, -1.8865e+00,\n",
       "          6.6632e-01,  5.3347e-01,  9.8037e-02, -1.7265e-01, -8.3175e-02,\n",
       "          1.9229e-01, -2.1317e+00,  1.6250e-01, -3.0908e-01,  6.9284e-01,\n",
       "         -3.2796e-02,  2.2771e+00,  1.6020e-01,  1.3506e+00,  1.4292e+00,\n",
       "          6.1975e-01,  1.0614e-01,  9.1325e-01,  1.6918e+00,  1.5962e-01,\n",
       "          9.3093e-01, -1.1185e+00,  6.9945e-01, -2.2617e-01, -2.7548e-01,\n",
       "         -1.3766e+00,  7.0044e-01,  1.4559e+00,  7.5166e-01, -1.6846e+00,\n",
       "          6.2337e-02,  2.7485e-01, -1.8088e+00, -1.4627e+00,  8.0852e-01,\n",
       "          1.0226e+00, -1.1661e-01,  8.9019e-01,  2.3807e-01,  1.0563e+00,\n",
       "         -2.0201e-01,  5.6728e-01,  5.3948e-01,  5.4596e-01, -8.0042e-01,\n",
       "         -6.4564e-01,  3.0119e-02,  2.4671e-01, -6.8126e-01, -1.6383e+00,\n",
       "         -1.4461e+00,  2.8709e-01,  9.5250e-01, -1.3346e+00,  6.8914e-01,\n",
       "         -2.1919e-01,  1.8559e-01,  2.1447e+00,  1.7118e+00,  4.0458e-01,\n",
       "         -9.3372e-01, -2.6237e-01,  7.4430e-01, -1.3200e+00,  2.1119e-01,\n",
       "          5.5833e-01, -3.4907e-01,  2.2161e+00, -5.3146e-01,  3.6221e-01,\n",
       "         -1.1052e+00, -3.3605e-01, -9.8308e-01,  1.8439e-02, -9.3563e-01,\n",
       "          9.6225e-01, -4.7241e-01,  7.7427e-01, -1.8609e+00, -1.0941e+00,\n",
       "          1.7933e-01, -8.8688e-01,  3.2946e-01, -2.3528e+00, -1.8260e-01],\n",
       "        [ 1.5143e-01, -1.1415e-01,  1.6500e+00,  7.8691e-01, -1.1525e+00,\n",
       "         -7.6759e-01,  1.2592e-02,  7.0447e-01, -2.7929e-01, -1.8207e+00,\n",
       "          1.1515e+00,  6.9629e-01,  2.2363e+00,  1.6498e-01, -1.2515e+00,\n",
       "          1.2560e+00,  4.8580e-01, -3.6469e-01,  1.9326e-01,  2.8810e+00,\n",
       "          1.4739e+00,  1.9474e-01,  8.0543e-02, -4.3289e-01,  1.0921e+00,\n",
       "          4.9976e-01,  2.0000e+00, -1.6357e+00,  1.6893e+00, -8.3629e-01,\n",
       "          6.0111e-01, -5.6235e-02, -5.7682e-01,  1.7889e-01, -4.9405e-01,\n",
       "         -4.7250e-01,  9.4711e-01, -2.0369e-01, -1.0395e+00, -5.0725e-01,\n",
       "          9.4666e-01,  5.2892e-01, -1.5266e-01,  2.2570e-01, -3.6897e-01,\n",
       "          5.2442e-01,  2.7895e+00,  2.8006e-01, -1.8263e+00,  8.5950e-01,\n",
       "         -4.2582e-01,  1.0460e+00, -3.1874e-01,  5.8745e-01, -1.1890e+00,\n",
       "         -1.7733e+00,  7.5560e-01, -1.1664e+00,  1.2532e-01, -1.6279e-01,\n",
       "         -2.1512e-02,  3.4582e-01,  3.8404e-01,  3.3415e-01,  8.5661e-02,\n",
       "         -4.2795e-01, -4.6461e-01, -5.2898e-02,  1.0958e+00,  3.8742e-01,\n",
       "         -1.1136e+00,  1.3195e+00, -3.4644e-01,  9.1466e-02,  1.4958e+00,\n",
       "         -2.0909e-01,  8.7565e-02, -8.1017e-01, -1.9901e-01,  1.1731e+00,\n",
       "         -1.0248e+00,  2.2370e-01,  1.1530e+00, -2.3112e-01,  1.3846e-01,\n",
       "          4.5732e-01,  2.0312e-01,  1.6745e-01, -1.1839e+00,  3.1875e-01,\n",
       "          1.2663e-01, -2.7544e-01, -7.1731e-02, -1.1200e+00,  4.2504e-01,\n",
       "         -1.2391e+00,  9.6432e-01,  1.2252e-01, -2.5129e+00, -8.2601e-01]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2308, -5.2266, -1.2130,  ...,  1.1677,  2.2364,  2.9948],\n",
       "        [ 0.9611,  2.5104,  0.3184,  ...,  0.8046,  0.0556, -0.5162],\n",
       "        [ 4.1471, 13.4126, -2.4888,  ..., -5.0624, -7.4518,  2.6197],\n",
       "        ...,\n",
       "        [-2.1596,  2.5529, -0.4397,  ...,  4.2037,  2.5266, -0.0152],\n",
       "        [ 4.9828,  8.5304, -5.1237,  ..., -7.9733, -6.3164,  3.6645],\n",
       "        [ 2.1378, -1.0517,  6.2649,  ..., -0.4926,  5.1390, -3.5473]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward \n",
    "\n",
    "\n",
    "torch.add(torch.matmul(X_train, w), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
